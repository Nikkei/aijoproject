{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "insight_gender_share.ipynb のコピー",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B77rHys0Ioi7"
      },
      "source": [
        "# mount Google Drive when you run on Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYEfD2w1ptnO"
      },
      "source": [
        "DATA_OFFSET = 0\n",
        "IMG_IN_FOLDER = False\n",
        "PATH_OUT = \"./output\"\n",
        "PATH_CSV = \"articles.csv\"\n",
        "PATH_DATA = \"./images/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XjxJysHJnyq"
      },
      "source": [
        "# change your directory to somewhere you put the codes\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dSwp-nEoKF5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import json\n",
        "from urllib import request\n",
        "import time\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75kIbhtmpG7G"
      },
      "source": [
        "# downloads files of insightface\n",
        "# git clone --recursive https://github.com/deepinsight/insightface.git\n",
        "#\n",
        "# upload files under aijoproject/insight-gender and insightface/gender-age to the same folder as this notebooke file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4jol-rFKBCi"
      },
      "source": [
        "# Enable GPU on Google Colab\n",
        "# !nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-YaDx9NKFAl"
      },
      "source": [
        "# install the lib for GPU and insightface\n",
        "!pip install mxnet-cu101\n",
        "!pip install --upgrade insightface"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuM81iQZq9fb"
      },
      "source": [
        "import insightface\n",
        "import face_model_aijo as face_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqK69ESQmiS9"
      },
      "source": [
        "model_retinaface = insightface.model_zoo.get_model(\"retinaface_r50_v1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoYkUA4ksf33"
      },
      "source": [
        "# Configure gender detection model\n",
        "model_retinaface.prepare(ctx_id=-1, nms=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlvoyAL88JeC"
      },
      "source": [
        "RESIZE_IMG_SIZE = 1024\n",
        "\n",
        "\n",
        "def resize_img(img):\n",
        "    (h, w) = img.shape[:2]\n",
        "    if h > w:\n",
        "        r = RESIZE_IMG_SIZE / float(h)\n",
        "        resized_image = cv2.resize(img, (int(r * w), RESIZE_IMG_SIZE))\n",
        "    else:\n",
        "        r = RESIZE_IMG_SIZE / float(w)\n",
        "        resized_image = cv2.resize(img, (RESIZE_IMG_SIZE, int(r * h)))\n",
        "    return resized_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSVwEO_6pEIy"
      },
      "source": [
        "def yield_image_paths_from_dir(image_dir):\n",
        "    image_dir = Path(image_dir)\n",
        "\n",
        "    img_list = []\n",
        "\n",
        "    for image_path in image_dir.glob(\"*.*\"):\n",
        "        img_list.append(str(image_path))\n",
        "\n",
        "    return img_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IErSuMVoaGG"
      },
      "source": [
        "class Args:\n",
        "    image_size = \"112,112\"\n",
        "    model = \"model/model,0\"\n",
        "    gpu = -1  # gpu id\n",
        "    det = 1  # mtcnn option, 1 means using R+O, 0 means detect from begining, 1 for threshold all 0 actually\n",
        "\n",
        "\n",
        "args = Args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWnSGb1Ur-iR"
      },
      "source": [
        "def find_faces_insightface(img, model):\n",
        "    ret_img = img.copy()\n",
        "    bboxes, _ = model.detect(img, threshold=0.7, scale=1.0)\n",
        "    return bboxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAfUAeWH0N-b"
      },
      "source": [
        "def fit_bbox_in_img(bbox, img):\n",
        "    bbox[0] = max(bbox[0], 0)\n",
        "    bbox[1] = max(bbox[1], 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiFgqEvkuNs_"
      },
      "source": [
        "from urllib.error import HTTPError\n",
        "\n",
        "\n",
        "def url_to_image(url):\n",
        "    try:\n",
        "        # download the image, convert it to a NumPy array, and then read\n",
        "        # it into OpenCV format\n",
        "        resp = request.urlopen(url)\n",
        "        image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "        # return the image\n",
        "        return image\n",
        "    except HTTPError as e:\n",
        "        print(\"{} error: {}\".format(e.code, url))\n",
        "        return None\n",
        "    except AttributeError:\n",
        "        print(\"attribution error\")\n",
        "        return None\n",
        "    except UnicodeEncodeError:\n",
        "        print(\"unicode encode error\")\n",
        "        return None\n",
        "    except ValueError:\n",
        "        print(\"value error\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKET7Y01_Dlh"
      },
      "source": [
        "def variance_of_laplacian(image):\n",
        "    # compute the Laplacian of the image and then return the focus\n",
        "    # measure, which is simply the variance of the Laplacian\n",
        "    return cv2.Laplacian(image, cv2.CV_64F).var()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8RLD93P669J"
      },
      "source": [
        "def calc_blur_level(img, size=100):\n",
        "    resized_img = cv2.resize(img, (size, size), interpolation=cv2.INTER_LINEAR)\n",
        "    return cv2.Laplacian(resized_img, cv2.CV_64F).var()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQdEgoFkpVnQ"
      },
      "source": [
        "article_info = pd.read_csv(PATH_CSV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvgfqX2OIuFs"
      },
      "source": [
        "if DATA_OFFSET == 0:\n",
        "    results_table = pd.DataFrame(\n",
        "        data=None,\n",
        "        index=None,\n",
        "        columns=[\"data_id\", \"article_id\", \"details\", \"image_size\"],\n",
        "    )\n",
        "else:\n",
        "    results_table = pd.read_csv(PATH_OUT + \"/results.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-32jsP0quZqA"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "for i_article in range(DATA_OFFSET, len(article_info)):\n",
        "\n",
        "    print(i_article)\n",
        "    people_in_img = []\n",
        "    kiji_id = str(article_info.at[i_article, \"article_id\"])\n",
        "    url = article_info.at[i_article, \"top_image_url\"]\n",
        "\n",
        "    # Read from folder or http\n",
        "    if IMG_IN_FOLDER:\n",
        "        image = cv2.imread(PATH_DATA + url)\n",
        "    else:\n",
        "        image = url_to_image(url)\n",
        "\n",
        "    if type(image) != np.ndarray:\n",
        "        continue\n",
        "\n",
        "    img_resized = resize_img(image)\n",
        "    face_bboxes, _ = model_retinaface.detect(img_resized, threshold=0.7, scale=1.0)\n",
        "\n",
        "    img_resized_boxed = img_resized.copy()\n",
        "\n",
        "    for i_face in range(len(face_bboxes)):\n",
        "        person_in_img_info = {}\n",
        "\n",
        "        face_bbox = face_bboxes[i_face]\n",
        "\n",
        "        # Fit bbox within the image\n",
        "        fit_bbox_in_img(face_bbox, img_resized)\n",
        "\n",
        "        img_resized_h, img_resized_w, _ = img_resized.shape\n",
        "\n",
        "        person_in_img_info[\"id\"] = i_article\n",
        "        person_in_img_info[\"face_conf_insight\"] = face_bbox[4]\n",
        "        person_in_img_info[\"face_area\"] = (\n",
        "            (face_bbox[2] - face_bbox[0])\n",
        "            * (face_bbox[3] - face_bbox[1])\n",
        "            / (img_resized_w * img_resized_h)\n",
        "        )\n",
        "        person_in_img_info[\"bbox\"] = [\n",
        "            face_bbox[0] / img_resized_w,\n",
        "            face_bbox[1] / img_resized_h,\n",
        "            face_bbox[2] / img_resized_w,\n",
        "            face_bbox[3] / img_resized_h,\n",
        "        ]  # '{0:.2f}'.format(pi)\n",
        "\n",
        "        face_img = img_resized[\n",
        "            int(face_bbox[1]) : int(face_bbox[3]) + 1,\n",
        "            int(face_bbox[0]) : int(face_bbox[2]) + 1,\n",
        "        ]  # img[y:y+h, x:x+w]\n",
        "        # show_small_img(face_img, 100)\n",
        "\n",
        "        blur_level = calc_blur_level(face_img)\n",
        "        person_in_img_info[\"blur_level\"] = blur_level\n",
        "        # print(blur_level)\n",
        "\n",
        "        img_h, img_w, _ = face_img.shape\n",
        "        args.image_size = str(img_w) + \",\" + str(img_h)\n",
        "\n",
        "        model_agender = face_model.FaceModel(args)\n",
        "        face_img_agender, agender_face_conf = model_agender.get_input(face_img)\n",
        "\n",
        "        person_in_img_info[\"face_conf_agender\"] = float(agender_face_conf)\n",
        "\n",
        "        if face_img_agender is None:\n",
        "            person_in_img_info[\"gender\"] = -1\n",
        "            person_in_img_info[\"age\"] = -1\n",
        "            cv2.rectangle(\n",
        "                img_resized_boxed,\n",
        "                (int(face_bbox[0]) - 2, int(face_bbox[1]) - 2),\n",
        "                (int(face_bbox[2]) + 2, int(face_bbox[3]) + 2),\n",
        "                (255, 255, 255),\n",
        "                4,\n",
        "            )\n",
        "            people_in_img.append(person_in_img_info)\n",
        "            continue\n",
        "\n",
        "        gender, age, g = model_agender.get_ga(face_img_agender)\n",
        "        person_in_img_info[\"gender\"] = int(gender)\n",
        "        person_in_img_info[\"age\"] = int(age)\n",
        "        person_in_img_info[\"gender_confidence\"] = [float(g[0]), float(g[1])]\n",
        "\n",
        "        color = (0, 255, 0) if gender == 1 else (0, 0, 255)\n",
        "        cv2.rectangle(\n",
        "            img_resized_boxed,\n",
        "            (int(face_bbox[0]) - 2, int(face_bbox[1]) - 2),\n",
        "            (int(face_bbox[2]) + 2, int(face_bbox[3]) + 2),\n",
        "            color,\n",
        "            4,\n",
        "        )\n",
        "\n",
        "        people_in_img.append(person_in_img_info)\n",
        "\n",
        "    if len(face_bboxes) > 0:\n",
        "        cv2.imwrite(PATH_OUT + \"/images/\" + kiji_id + \".jpg\", img_resized)\n",
        "\n",
        "    results_table = results_table.append(\n",
        "        {\n",
        "            \"data_id\": i_article,\n",
        "            \"article_id\": kiji_id,\n",
        "            \"details\": json.dumps(people_in_img, ensure_ascii=False),\n",
        "            \"image_size\": json.dumps(image.shape),\n",
        "        },\n",
        "        ignore_index=True,\n",
        "    )\n",
        "\n",
        "    if i_article % 10 == 0:\n",
        "        results_table.to_csv(PATH_OUT + \"/results.csv\", index=False)\n",
        "\n",
        "results_table.to_csv(PATH_OUT + \"/results.csv\", index=False)\n",
        "\n",
        "elapsed_time = time.time() - start\n",
        "print(\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWYqBw5FpG7I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}