{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYEfD2w1ptnO"
   },
   "outputs": [],
   "source": [
    "DATA_OFFSET = 0\n",
    "IMG_IN_FOLDER = False\n",
    "PATH_OUT = \"./output\"\n",
    "PATH_CSV = \"articles.csv\"\n",
    "PATH_DATA = \"./images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dSwp-nEoKF5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from urllib import request\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B77rHys0Ioi7",
    "outputId": "755e7a80-7f6a-4c02-a58f-abd43c32f446"
   },
   "outputs": [],
   "source": [
    "# mount Google Drive when you run on Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3XjxJysHJnyq",
    "outputId": "e0a90647-503b-4173-a2c3-d2fd526617a5"
   },
   "outputs": [],
   "source": [
    "# change your directory to somewhere you put the codes\n",
    "# %cd /content/drive/My\\ Drive/somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4jol-rFKBCi",
    "outputId": "f44034c4-71e8-41f6-d2d0-722378788e6f"
   },
   "outputs": [],
   "source": [
    "# Enable GPU on Google Colab\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-YaDx9NKFAl",
    "outputId": "f446ae43-c47d-4938-c8a1-4da9f59f7859"
   },
   "outputs": [],
   "source": [
    "# install the lib for GPU and insightface\n",
    "# !pip install mxnet-cu101\n",
    "# !pip install --upgrade insightface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuM81iQZq9fb"
   },
   "outputs": [],
   "source": [
    "import insightface\n",
    "import face_model_aijo as face_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqK69ESQmiS9",
    "outputId": "610bd49c-b40e-49dc-f615-017cea82c47e"
   },
   "outputs": [],
   "source": [
    "model_retinaface = insightface.model_zoo.get_model(\"retinaface_r50_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoYkUA4ksf33",
    "outputId": "3c0c2fc0-b985-439a-f6e3-42479964303d"
   },
   "outputs": [],
   "source": [
    "# Configure gender detection model\n",
    "model_retinaface.prepare(ctx_id=-1, nms=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlvoyAL88JeC"
   },
   "outputs": [],
   "source": [
    "RESIZE_IMG_SIZE = 1024\n",
    "\n",
    "\n",
    "def resize_img(img):\n",
    "    (h, w) = img.shape[:2]\n",
    "    if h > w:\n",
    "        r = RESIZE_IMG_SIZE / float(h)\n",
    "        resized_image = cv2.resize(img, (int(r * w), RESIZE_IMG_SIZE))\n",
    "    else:\n",
    "        r = RESIZE_IMG_SIZE / float(w)\n",
    "        resized_image = cv2.resize(img, (RESIZE_IMG_SIZE, int(r * h)))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSVwEO_6pEIy"
   },
   "outputs": [],
   "source": [
    "def yield_image_paths_from_dir(image_dir):\n",
    "    image_dir = Path(image_dir)\n",
    "\n",
    "    img_list = []\n",
    "\n",
    "    for image_path in image_dir.glob(\"*.*\"):\n",
    "        img_list.append(str(image_path))\n",
    "\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IErSuMVoaGG"
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    image_size = \"112,112\"\n",
    "    model = \"model/model,0\"\n",
    "    gpu = -1  # gpu id\n",
    "    det = 1  # mtcnn option, 1 means using R+O, 0 means detect from begining, 1 for threshold all 0 actually\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWnSGb1Ur-iR"
   },
   "outputs": [],
   "source": [
    "def find_faces_insightface(img, model):\n",
    "    ret_img = img.copy()\n",
    "    bboxes, _ = model.detect(img, threshold=0.7, scale=1.0)\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAfUAeWH0N-b"
   },
   "outputs": [],
   "source": [
    "def fit_bbox_in_img(bbox, img):\n",
    "    bbox[0] = max(bbox[0], 0)\n",
    "    bbox[1] = max(bbox[1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiFgqEvkuNs_"
   },
   "outputs": [],
   "source": [
    "from urllib.error import HTTPError\n",
    "\n",
    "\n",
    "def url_to_image(url):\n",
    "    try:\n",
    "        # download the image, convert it to a NumPy array, and then read\n",
    "        # it into OpenCV format\n",
    "        resp = request.urlopen(url)\n",
    "        image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        # return the image\n",
    "        return image\n",
    "    except HTTPError as e:\n",
    "        print(\"{} error: {}\".format(e.code, url))\n",
    "        return None\n",
    "    except AttributeError:\n",
    "        print(\"attribution error\")\n",
    "        return None\n",
    "    except UnicodeEncodeError:\n",
    "        print(\"unicode encode error\")\n",
    "        return None\n",
    "    except ValueError:\n",
    "        print(\"value error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKET7Y01_Dlh"
   },
   "outputs": [],
   "source": [
    "def variance_of_laplacian(image):\n",
    "    # compute the Laplacian of the image and then return the focus\n",
    "    # measure, which is simply the variance of the Laplacian\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8RLD93P669J"
   },
   "outputs": [],
   "source": [
    "def calc_blur_level(img, size=100):\n",
    "    resized_img = cv2.resize(img, (size, size), interpolation=cv2.INTER_LINEAR)\n",
    "    return cv2.Laplacian(resized_img, cv2.CV_64F).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQdEgoFkpVnQ"
   },
   "outputs": [],
   "source": [
    "article_info = pd.read_csv(PATH_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvgfqX2OIuFs"
   },
   "outputs": [],
   "source": [
    "if DATA_OFFSET == 0:\n",
    "    results_table = pd.DataFrame(\n",
    "        data=None,\n",
    "        index=None,\n",
    "        columns=[\"data_id\", \"article_id\", \"details\", \"image_size\"],\n",
    "    )\n",
    "else:\n",
    "    results_table = pd.read_csv(PATH_OUT + \"/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-32jsP0quZqA",
    "outputId": "954b19de-3ad5-4be6-dc29-aa08860a3532"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i_article in range(DATA_OFFSET, len(article_info)):\n",
    "\n",
    "    print(i_article)\n",
    "    people_in_img = []\n",
    "    kiji_id = str(article_info.at[i_article, \"article_id\"])\n",
    "    url = article_info.at[i_article, \"top_image_url\"]\n",
    "\n",
    "    # Read from folder or http\n",
    "    if IMG_IN_FOLDER:\n",
    "        image = cv2.imread(PATH_DATA + url)\n",
    "    else:\n",
    "        image = url_to_image(url)\n",
    "\n",
    "    if type(image) != np.ndarray:\n",
    "        continue\n",
    "\n",
    "    img_resized = resize_img(image)\n",
    "    face_bboxes, _ = model_retinaface.detect(img_resized, threshold=0.7, scale=1.0)\n",
    "\n",
    "    img_resized_boxed = img_resized.copy()\n",
    "\n",
    "    for i_face in range(len(face_bboxes)):\n",
    "        person_in_img_info = {}\n",
    "\n",
    "        face_bbox = face_bboxes[i_face]\n",
    "\n",
    "        # Fit bbox within the image\n",
    "        fit_bbox_in_img(face_bbox, img_resized)\n",
    "\n",
    "        img_resized_h, img_resized_w, _ = img_resized.shape\n",
    "\n",
    "        person_in_img_info[\"id\"] = i_article\n",
    "        person_in_img_info[\"face_conf_insight\"] = face_bbox[4]\n",
    "        person_in_img_info[\"face_area\"] = (\n",
    "            (face_bbox[2] - face_bbox[0])\n",
    "            * (face_bbox[3] - face_bbox[1])\n",
    "            / (img_resized_w * img_resized_h)\n",
    "        )\n",
    "        person_in_img_info[\"bbox\"] = [\n",
    "            face_bbox[0] / img_resized_w,\n",
    "            face_bbox[1] / img_resized_h,\n",
    "            face_bbox[2] / img_resized_w,\n",
    "            face_bbox[3] / img_resized_h,\n",
    "        ]  # '{0:.2f}'.format(pi)\n",
    "\n",
    "        face_img = img_resized[\n",
    "            int(face_bbox[1]) : int(face_bbox[3]) + 1,\n",
    "            int(face_bbox[0]) : int(face_bbox[2]) + 1,\n",
    "        ]  # img[y:y+h, x:x+w]\n",
    "        # show_small_img(face_img, 100)\n",
    "\n",
    "        blur_level = calc_blur_level(face_img)\n",
    "        person_in_img_info[\"blur_level\"] = blur_level\n",
    "        # print(blur_level)\n",
    "\n",
    "        img_h, img_w, _ = face_img.shape\n",
    "        args.image_size = str(img_w) + \",\" + str(img_h)\n",
    "\n",
    "        model_agender = face_model.FaceModel(args)\n",
    "        face_img_agender, agender_face_conf = model_agender.get_input(face_img)\n",
    "\n",
    "        person_in_img_info[\"face_conf_agender\"] = float(agender_face_conf)\n",
    "\n",
    "        if face_img_agender is None:\n",
    "            person_in_img_info[\"gender\"] = -1\n",
    "            person_in_img_info[\"age\"] = -1\n",
    "            cv2.rectangle(\n",
    "                img_resized_boxed,\n",
    "                (int(face_bbox[0]) - 2, int(face_bbox[1]) - 2),\n",
    "                (int(face_bbox[2]) + 2, int(face_bbox[3]) + 2),\n",
    "                (255, 255, 255),\n",
    "                4,\n",
    "            )\n",
    "            people_in_img.append(person_in_img_info)\n",
    "            continue\n",
    "\n",
    "        gender, age, g = model_agender.get_ga(face_img_agender)\n",
    "        person_in_img_info[\"gender\"] = int(gender)\n",
    "        person_in_img_info[\"age\"] = int(age)\n",
    "        person_in_img_info[\"gender_confidence\"] = [float(g[0]), float(g[1])]\n",
    "\n",
    "        color = (0, 255, 0) if gender == 1 else (0, 0, 255)\n",
    "        cv2.rectangle(\n",
    "            img_resized_boxed,\n",
    "            (int(face_bbox[0]) - 2, int(face_bbox[1]) - 2),\n",
    "            (int(face_bbox[2]) + 2, int(face_bbox[3]) + 2),\n",
    "            color,\n",
    "            4,\n",
    "        )\n",
    "\n",
    "        people_in_img.append(person_in_img_info)\n",
    "\n",
    "    if len(face_bboxes) > 0:\n",
    "        cv2.imwrite(PATH_OUT + \"/images/\" + kiji_id + \".jpg\", img_resized)\n",
    "\n",
    "    results_table = results_table.append(\n",
    "        {\n",
    "            \"data_id\": i_article,\n",
    "            \"article_id\": kiji_id,\n",
    "            \"details\": json.dumps(people_in_img, ensure_ascii=False),\n",
    "            \"image_size\": json.dumps(image.shape),\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    if i_article % 10 == 0:\n",
    "        results_table.to_csv(PATH_OUT + \"/results.csv\", index=False)\n",
    "\n",
    "results_table.to_csv(PATH_OUT + \"/results.csv\", index=False)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "print(\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "insight_gender_share.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
